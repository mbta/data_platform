
# used ubuntu here for ease of use
FROM ubuntu:20.04

# make java install non interactive by preseting the timezone
ARG DEBIAN_FRONTEND=noninteractive
ENV TZ=US/Eastern

# install dependencies for running spark 2.4.x
RUN apt update
RUN apt install -y software-properties-common git curl openjdk-8-jdk-headless zip maven
# fetch specific python version as needed for spark
RUN add-apt-repository ppa:deadsnakes/ppa
RUN apt update
RUN apt install -y python3.7 python3.7-dev python3.7-distutils
# symlink so spark uses the right version (ubuntu has python3 installed)
RUN ln -s -f /usr/bin/python3.7 /usr/bin/python
RUN ln -s -f /usr/bin/python3.7 /usr/bin/python3
# install pip since it's not available in the docker image
RUN curl https://bootstrap.pypa.io/get-pip.py --output get-pip.py
RUN python get-pip.py

# install (clone) glue, and work with master, which currently is glue 3.0
RUN git clone --branch master https://github.com/awslabs/aws-glue-libs.git /glue
# fetch and extract glue-provided archive for spark
RUN curl https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-3.0/spark-3.1.1-amzn-0-bin-3.2.1-amzn-3.tgz --output apache-spark.tgz
RUN tar --no-same-owner -xf apache-spark.tgz

# set env variables that spark needs, and run it to ensure maven has fetched what it needs
ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
ENV SPARK_HOME=/spark-3.1.1-amzn-0-bin-3.2.1-amzn-3
RUN /glue/bin/gluesparksubmit --version

# python packaging
RUN pip install poetry
# install py_cubic_ingestion's required python dependencies
COPY ./py_cubic_ingestion /data_platform/py_cubic_ingestion
WORKDIR /data_platform/py_cubic_ingestion
RUN poetry config virtualenvs.create false
RUN poetry install
# install an editable link of py_cubic_ingestion
RUN pip install --editable .

CMD ["echo", "Container 'glue__local' ready!"]
